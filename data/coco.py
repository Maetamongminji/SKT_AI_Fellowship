# -*- coding: utf-8 -*-
"""COCO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v7mKIZPb2XjS7O53nBaqC8JEbmwEw9xe

py파일로 저장해서 ups -> data 아래 위치로 commit할 것

+ 이 안에 get_coco class 만들 것
+ COCOSSL class도!

### __Checking GPU informations__
"""

'''

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Select the Runtime > "Change runtime type" menu to enable a GPU accelerator, ')
  print('and then re-execute this cell.')
else:
  print(gpu_info)

'''

import warnings
warnings.filterwarnings('ignore')

"""### __Google Drive Mount__"""

from google.colab import drive
drive.mount('/content/drive')

"""### __Changing directory & Git Cloning__"""

cd /content/drive/MyDrive/SKT/ups/

import numpy as np
from PIL import Image
from torchvision import datasets
from torchvision import transforms
from data.augmentations import *  
# ShearX, ShearY, TranslateX, TranslateXabs, TranslateY, TranslateYabs, Rotate, AutoContrast, Invert, Equalize, Flip, Solarize, SolarizeAdd, Posterize, 
# Contrast, Color, Brightness, Sharpness, Cutout, CutoutAbs, SamplePairing, Identity, augment_list, Lighting, CutoutDefault, CutoutRandom, RandAugment
# Above are defined classes in 'ups/augmentations.py' (All imported)

import pickle
import os

# !git clone https://github.com/Maetamongminji/SKT_AI_Fellowship.git # already cloned

"""### __Unzip files in G-Drive(DONE)__"""

# cd /content/drive/MyDrive/SKT_AI_Fellowship/ups/data/datasets/coco-2017

'''
# done!

!unzip -qq '/content/drive/MyDrive/SKT_AI_Fellowship/ups/data/datasets/coco-2017/annotations_trainval2017.zip'
!unzip -qq '/content/drive/MyDrive/SKT_AI_Fellowship/ups/data/datasets/coco-2017/train2017.zip'
!unzip -qq '/content/drive/MyDrive/SKT_AI_Fellowship/ups/data/datasets/coco-2017/val2017.zip'
!unzip -qq '/content/drive/MyDrive/SKT_AI_Fellowship/ups/data/datasets/coco-2017/test2017.zip'
'''

"""#### __Downloading dataset using Python API(tried but failed)__"""

# !pip install numpy cython

# !git clone https://github.com/cocodataset/cocoapi.git

# cd /content/drive/MyDrive/SKT_AI_Fellowship/cocoapi/PythonAPI

"""#### __Getting dataset using FiftyOne zoo(tried but failed)__"""

# !sudo python3 setup.py build_ext install

"""
- fiftyone installing 할 때 botocore 랑 urllib3 랑 버전 충돌 일어나서 미리 urllib 버전 맞춰줘야 함  
- error message  
ERROR: botocore 1.20.105 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.  """

'''

pip install --upgrade urllib3==1.25.11
pip install fiftyone # All requirements are satisfied

'''

'''

import fiftyone as fo
import fiftyone.zoo as foz

# List available zoo datasets 
# 
print(foz.list_zoo_datasets(), '\n') # 'coco-2014', 'coco-2017' are also in the list

#
# Load the COCO-2017 validation split into a FiftyOne dataset
#
# This will download the dataset from the web, if necessary
#
dataset = foz.load_zoo_dataset("coco-2017",
                               label_types = "detections",
                               classes = "person",
                               split = "train") # 먼저 coco-2017만 써보자 # max_samples 따로 설정해주지 않았기 때문에 디폴트로 모든 가능한 sample 뽑음

# Give the dataset a new name, and make it persistent so that you can
# work with it in future sessions

dataset.name = "coco-2017-train-all"
dataset.persistent = True

# Visualize the dataset in the App
session_valid = fo.launch_app(dataset)

'''

### fuouo

'''
import fiftyone.utils.openimages as fouo
import pandas as pd


class_list = fouo.get_classes()
class_series = pd.Series(class_list)
'''

'''
class_series[260:272] # 260~271까지가 Human 에 대한 것
'''

'''

# Load the COCO-2017 validation split into a FiftyOne dataset
#
# This will download the dataset from the web, if necessary
#
dataset = foz.load_zoo_dataset("coco-2017", 
                               split="train",
                               max_samples = 10000) # 너무 오래 걸려 일단 만 개로 테스트

# Give the dataset a new name, and make it persistent so that you can
# work with it in future sessions
# max sample 따로 설정해주지 않았기 때문에 디폴트로 모든 가능한 sample 뽑는 것으로...!
dataset.name = "coco-2017-train-example"
dataset.persistent = True
'''

# Visualize the in the App
# session = fo.launch_app(dataset) # coco-2017-train-example

"""cifar-10, cifar-100 이용했을 때 main class에서 RuntimeError 뜸

  File "train-cifar.py", line 277, in <module>
    main()
  File "train-cifar.py", line 228, in main
    test_loss, test_acc = test(args, test_loader, test_model)
  File "/content/drive/MyDrive/SKT_AI_Fellowship/ups/utils/evaluate.py", line 32, in test
    prec1, prec5 = accuracy(outputs, targets, topk=(1, 5))
  File "/content/drive/MyDrive/SKT_AI_Fellowship/ups/utils/misc.py", line 41, in accuracy
    correct_k = correct[:k].view(-1).float().sum(0)
RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.
  0% 0/79 [00:00<?, ?it/s]

--> 에러 해결법은 view ftn 대신 reshape ftn 써주는 것(utils의 misc.py 안에 있는 accuracy class 안의 view -> reshape으로 변경)

### __Getting Data from G-Drive__
"""

# cd /content/drive/MyDrive/SKT_AI_Fellowship/ups/data/datasets/coco-2017/

# print(os.getcwd())

'''
dir_coco_2017 = '/content/drive/MyDrive/SKT_AI_Fellowship/ups/data/datasets/coco-2017/'
print(os.listdir(dir_coco_2017))
'''

"""- train2017: 
- val2017: 5000 images(jpg format)
- test2017: 
- annotations: 6 json files(captions, instances, person_keypoints files for training and validation each)
  - captions: 텍스트로 된 그림에 대한 설명
  - **instances: 그림에 있는 사람/사물에 대한 category와 영역 mask**
  - person_keypoint: 사람의 자세 데이터
"""

class COCOSSL(datasets.CocoDetection):
    def __init__(self, root, indexs, train=True,
                 transform=None, target_transform=None,
                 download=True, pseudo_idx=None, pseudo_target=None,
                 nl_idx=None, nl_mask=None):
        super().__init__(root, train=train,
                         transform=transform,
                         target_transform=target_transform,
                         download=download)
        
        self.targets = np.array(self.targets)
        self.nl_mask = np.ones((len(self.targets), len(np.unique(self.targets))))
        
        if nl_mask is not None:
            self.nl_mask[nl_idx] = nl_mask

        if pseudo_target is not None:
            self.targets[pseudo_idx] = pseudo_target

        if indexs is not None:
            indexs = np.array(indexs)
            self.data = self.data[indexs]
            self.targets = np.array(self.targets)[indexs]
            self.nl_mask = np.array(self.nl_mask)[indexs]
            self.indexs = indexs
        else:
            self.indexs = np.arange(len(self.targets))
        

    def __getitem__(self, index):
        img, target = self.data[index], self.targets[index]
        img = Image.fromarray(img)

        if self.transform is not None:
            img = self.transform(img)

        if self.target_transform is not None:
            target = self.target_transform(target)

        return img, target, self.indexs[index], self.nl_mask[index]

def lbl_unlbl_split(lbls, n_lbl, n_class):
    lbl_per_class = n_lbl // n_class
    lbls = np.array(lbls)
    lbl_idx = []
    unlbl_idx = []
    for i in range(n_class):
        idx = np.where(lbls == i)[0]
        np.random.shuffle(idx)
        lbl_idx.extend(idx[:lbl_per_class])
        unlbl_idx.extend(idx[lbl_per_class:])
    return lbl_idx, unlbl_idx

# dir_coco_2017 = '/content/drive/MyDrive/SKT_AI_Fellowship/ups/data/datasets/coco-2017/'

# dir_coco_2017 + 'train2017/'

"""___
__Why M=3, N=4 are selected?__

- CIFAR-10 has been extensively studied with previous
data augmentation methods and we first test this proposed
method on this data. The default augmentations for all
methods include flips, pad-and-crop and Cutout [8]. N and
M were selected based on the validation performance on 5K
held out examples from the training set for 1 and 5 settings
for N and M, respectively. Results indicate that RandAugment achieves either competitive (i.e. within 0.1%) or stateof-the-art on CIFAR-10 across four network architectures
(Table 2). As a more challenging task, we additionally compare the efficacy of RandAugment on CIFAR-100 for WideResNet-28-2 and Wide-ResNet-28-10. On the held out 5K
dataset, we sampled 2 and 4 settings for N and M, respectively (i.e. N={1, 2} and M={2, 6, 10, 14}). For WideResNet-28-2 and Wide-ResNet-28-10, we find that N=1,
M=2 and N=2, M=14 achieves best results, respectively.
Again, RandAugment achieves competitive or superior results across both architectures (Table 2).
  

   from https://arxiv.org/pdf/1909.13719.pdf
"""

def get_coco(root=datasets, n_lbl=4000, ssl_idx=None, pseudo_lbl=None, itr=0, split_txt=''):
    os.makedirs(root, exist_ok=True) #create the root directory for saving data

    # augmentations
    transform_train = transforms.Compose([
        RandAugment(3,4),  
        #from https://arxiv.org/pdf/1909.13719.pdf. For CIFAR-10 M=3, N=4
        #위에 추가 설명

        transforms.RandomHorizontalFlip(),
        transforms.RandomCrop(size=400, padding=int(160*0.125), padding_mode='reflect'), # COCO는 640x480이라 함 
        transforms.ColorJitter(
            brightness=0.4,
            contrast=0.4,
            saturation=0.4,
        ),
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2435, 0.2616)),
        CutoutRandom(n_holes=1, length=16, random=True)
    ])
    
    transform_val = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2435, 0.2616))
    ])

    if ssl_idx is None:
        # Read from Google Drive
        I = io.imread(base_dataset%(dataType,img['file_name']))
        base_dataset = datasets.CocoDetection(root, train=True, download=True)
        train_lbl_idx, train_unlbl_2idx = lbl_unlbl_split(base_dataset.targets , n_lbl, 10)
        os.makedirs('data/splits', exist_ok=True)
        f = open(os.path.join('data/splits', 'cifar10_basesplit_{n_lbl}_{split_txt}.pkl'),"wb")
        lbl_unlbl_dict = {'lbl_idx': train_lbl_idx, 'unlbl_idx': train_unlbl_idx}
        pickle.dump(lbl_unlbl_dict,f)
    
    else:
        lbl_unlbl_dict = pickle.load(open(ssl_idx, 'rb'))
        train_lbl_idx = lbl_unlbl_dict['lbl_idx']
        train_unlbl_idx = lbl_unlbl_dict['unlbl_idx']

    lbl_idx = train_lbl_idx
    if pseudo_lbl is not None:
        pseudo_lbl_dict = pickle.load(open(pseudo_lbl, 'rb'))
        pseudo_idx = pseudo_lbl_dict['pseudo_idx']
        pseudo_target = pseudo_lbl_dict['pseudo_target']
        nl_idx = pseudo_lbl_dict['nl_idx']
        nl_mask = pseudo_lbl_dict['nl_mask']
        lbl_idx = np.array(lbl_idx + pseudo_idx)

        #balance the labeled and unlabeled data 
        if len(nl_idx) > len(lbl_idx):
            exapand_labeled = len(nl_idx) // len(lbl_idx)
            lbl_idx = np.hstack([lbl_idx for _ in range(exapand_labeled)])

            if len(lbl_idx) < len(nl_idx):
                diff = len(nl_idx) - len(lbl_idx)
                lbl_idx = np.hstack((lbl_idx, np.random.choice(lbl_idx, diff)))
            else:
                assert len(lbl_idx) == len(nl_idx)
    else:
        pseudo_idx = None
        pseudo_target = None
        nl_idx = None
        nl_mask = None

    train_lbl_dataset = COCOSSL(
        root, lbl_idx, train=True, transform=transform_train,
        pseudo_idx=pseudo_idx, pseudo_target=pseudo_target,
        nl_idx=nl_idx, nl_mask=nl_mask)
    
    if nl_idx is not None:
        train_nl_dataset = COCOSSL(
            root, np.array(nl_idx), train=True, transform=transform_train,
            pseudo_idx=pseudo_idx, pseudo_target=pseudo_target,
            nl_idx=nl_idx, nl_mask=nl_mask)

    train_unlbl_dataset = COCOSSL(
    root, train_unlbl_idx, train=True, transform=transform_val)

    test_dataset = datasets.CocoDetection(root, train=False, transform=transform_val, download=True)

    if nl_idx is not None:
        return train_lbl_dataset, train_nl_dataset, train_unlbl_dataset, test_dataset
    else:
        return train_lbl_dataset, train_unlbl_dataset, train_unlbl_dataset, test_dataset

os.getcwd()

cd /content/drive/MyDrive/SKT/ups/SKT_AI_Fellowship

os.getcwd()

!pwd

!ls

# For CIFAR10 4000 Labels
!python3 train_coco.py --dataset "coco" --n-lbl 4000 --class-blnc 7 --split-txt "run1" --arch "cnn13"

# For CIFAR10 1000 Labels
!python3 train_coco.py --dataset "coco" --n-lbl 10000 --class-blnc 7 --split-txt "run1" --arch "cnn13"

# For CIFAR100 10000 Labels
!python3 train_coco.py --dataset "coco" --n-lbl 10000 --class-blnc 1 --split-txt "run1" --arch "cnn13"

# For CIFAR100 4000 Labels
!python3 train_coco.py --dataset "coco" --n-lbl 4000 --class-blnc 1 --split-txt "run1" --arch "cnn13"

